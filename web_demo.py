"""
@license AGPL-3.0
Copyright (c) 2025 ShatteredCross. All rights reserved.
"""
from datetime import datetime
import os
import tempfile
import shutil
from pathlib import Path
import gradio as gr
from transformers import AutoProcessor, Qwen2VLForConditionalGeneration
from PIL import Image
from mineru_vl_utils import MinerUClient

# å…¨å±€å˜é‡ï¼Œç”¨äºä¿å­˜æ¨¡å‹å’Œå®¢æˆ·ç«¯
global_model = None
global_processor = None
global_client = None

try:
    from pdf2image import convert_from_path
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False

# å¤šè¯­è¨€æ–‡æœ¬å®šä¹‰
TEXTS = {
    "zh": {
        "title": "PDF OCR based on MinerU2.5-1.2B",
        "subtitle": "åŸºäº MinerU2.5-1.2B OCR å¤§æ¨¡å‹çš„ PDF å’Œå›¾ç‰‡æ–‡æ¡£è¯†åˆ«å·¥å…·",
        "model_path_label": "æ¨¡å‹è·¯å¾„",
        "model_path_placeholder": "è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„...ï¼ˆå¦‚ä¸ºDocker,è¾“å…¥ /app/checkpoints ï¼‰",
        "load_model_btn": "åŠ è½½æ¨¡å‹",
        "file_input_label": "ä¸Šä¼ æ–‡ä»¶",
        "process_btn": "å¼€å§‹OCRè¯†åˆ«",
        "status_output_label": "å¤„ç†çŠ¶æ€",
        "result_output_label": "è¯†åˆ«ç»“æœ (Markdownæ ¼å¼)",
        "file_output_label": "ä¸‹è½½ç»“æœæ–‡ä»¶",
        "instructions_title": "ä½¿ç”¨è¯´æ˜",
        "instructions": [
            "1. **è®¾ç½®æ¨¡å‹è·¯å¾„**: è¾“å…¥ `MinerU2.5-1.2B` æ¨¡å‹æ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„ï¼ˆå¦‚ä¸ºDocker,è¾“å…¥ /app/checkpoints ï¼‰",
            "2. **ç‚¹å‡»åŠ è½½æ¨¡å‹**: ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆï¼ˆçŠ¶æ€æ æ˜¾ç¤ºæˆåŠŸï¼‰",
            "3. **ä¸Šä¼ æ–‡ä»¶**: æ”¯æŒ PDFã€JPGã€JPEGã€PNGã€BMP æ ¼å¼",
            "4. **å¼€å§‹è¯†åˆ«**: ç‚¹å‡»å¼€å§‹OCRè¯†åˆ«æŒ‰é’®ï¼Œç­‰å¾…å¤„ç†å®Œæˆ",
            "5. **æŸ¥çœ‹ç»“æœ**: åœ¨å³ä¾§æŸ¥çœ‹è¯†åˆ«ç»“æœå’Œä¸‹è½½Markdownæ–‡ä»¶"
        ],
        "supported_formats_title": "æ”¯æŒçš„æ ¼å¼",
        "supported_formats": [
            "PDF æ–‡æ¡£ï¼ˆå¤šé¡µè‡ªåŠ¨å¤„ç†ï¼‰",
            "å›¾ç‰‡æ–‡ä»¶: JPG, JPEG, PNG, BMP"
        ],
        "notes_title": "æ³¨æ„äº‹é¡¹",
        "notes": [
            "å¤„ç†å¤§å‹PDFæ–‡ä»¶å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´",
            "ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®ä¸”åŒ…å«å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶"
        ],
        "language_btn": "English",
        # æ–°å¢çš„çŠ¶æ€å’Œé”™è¯¯ä¿¡æ¯
        "model_not_loaded": "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹ï¼ç‚¹å‡»ä¸Šæ–¹çš„'åŠ è½½æ¨¡å‹'æŒ‰é’®å®Œæˆæ¨¡å‹åˆå§‹åŒ–åå†è¿›è¡ŒOCRè¯†åˆ«ã€‚",
        "no_file_uploaded": "âŒ è¯·å…ˆä¸Šä¼ è¦è¯†åˆ«çš„æ–‡ä»¶ï¼",
        "pdf_not_supported": "âŒ PDFæ”¯æŒæœªå¯ç”¨ï¼Œè¯·å®‰è£…pdf2image: pip install pdf2image",
        "unsupported_format": "âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ {file_ext}",
        "file_detected": "ğŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶: {filename}",
        "pdf_detected": "ğŸ”„ æ£€æµ‹åˆ°PDFæ–‡ä»¶ï¼Œå¼€å§‹è½¬æ¢...",
        "pdf_converted": "âœ… PDFè½¬æ¢å®Œæˆï¼Œå…± {page_count} é¡µ",
        "image_detected": "ğŸ–¼ï¸ æ£€æµ‹åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...",
        "page_processed": "âœ… ç¬¬ {page_num} é¡µå¤„ç†å®Œæˆ",
        "image_processed": "âœ… å›¾ç‰‡å¤„ç†å®Œæˆ",
        "ocr_completed": "âœ… OCRå¤„ç†å®Œæˆ! ç»“æœä¿å­˜åœ¨: {filename}",
        "processing_error": "âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {error}",
        "model_loading": "æ­£åœ¨åŠ è½½æ¨¡å‹...",
        "processor_loading": "æ­£åœ¨åŠ è½½å¤„ç†å™¨...",
        "client_initializing": "æ­£åœ¨åˆå§‹åŒ–å®¢æˆ·ç«¯...",
        "model_loaded": "æ¨¡å‹åŠ è½½å®Œæˆ",
        "model_load_success": "âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼",
        "model_path_not_exist": "âŒ é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨",
        "model_load_failed": "âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {error}",
        "pdf_converting": "æ­£åœ¨è½¬æ¢PDFä¸ºå›¾ç‰‡...",
        "processing_page": "æ­£åœ¨å¤„ç†ç¬¬ {page_num} é¡µ...",
        "processing_image": "æ­£åœ¨å¤„ç†å›¾ç‰‡...",
        "generating_markdown": "æ­£åœ¨ç”ŸæˆMarkdownæ–‡ä»¶...",
        "processing_complete": "å¤„ç†å®Œæˆ"
    },
    "en": {
        "title": "PDF OCR based on MinerU2.5-1.2B",
        "subtitle": "PDF and Image OCR Tool based on MinerU2.5-1.2B Model",
        "model_path_label": "Model Path",
        "model_path_placeholder": "Please enter the absolute path to the model directory...(For Docker, input /app/checkpoints)",
        "load_model_btn": "Load Model",
        "file_input_label": "Upload File",
        "process_btn": "Start OCR Recognition",
        "status_output_label": "Processing Status",
        "result_output_label": "Recognition Result (Markdown Format)",
        "file_output_label": "Download Result File",
        "instructions_title": "Usage Instructions",
        "instructions": [
            "1. **Set Model Path**: Enter the absolute path to the `MinerU2.5-1.2B` model directory (For Docker, input /app/checkpoints)",
            "2. **Click Load Model**: Wait for model loading to complete (status bar shows success)",
            "3. **Upload File**: Supports PDF, JPG, JPEG, PNG, BMP formats",
            "4. **Start Recognition**: Click the Start OCR Recognition button and wait for processing to complete",
            "5. **View Results**: Check the recognition results and download Markdown file on the right"
        ],
        "supported_formats_title": "Supported Formats",
        "supported_formats": [
            "PDF documents (multi-page automatic processing)",
            "Image files: JPG, JPEG, PNG, BMP"
        ],
        "notes_title": "Notes",
        "notes": [
            "Processing large PDF files may take a long time",
            "Ensure the model path is correct and contains complete model files"
        ],
        "language_btn": "ä¸­æ–‡",
        # çŠ¶æ€å’Œé”™è¯¯ä¿¡æ¯
        "model_not_loaded": "âŒ Please load the model first! Click the 'Load Model' button above to complete model initialization before OCR recognition.",
        "no_file_uploaded": "âŒ Please upload a file to recognize first!",
        "pdf_not_supported": "âŒ PDF support is not enabled, please install pdf2image: pip install pdf2image",
        "unsupported_format": "âŒ Unsupported file format {file_ext}",
        "file_detected": "ğŸ“„ File detected: {filename}",
        "pdf_detected": "ğŸ”„ PDF file detected, starting conversion...",
        "pdf_converted": "âœ… PDF conversion completed, total {page_count} pages",
        "image_detected": "ğŸ–¼ï¸ Image file detected, starting processing...",
        "page_processed": "âœ… Page {page_num} processed",
        "image_processed": "âœ… Image processing completed",
        "ocr_completed": "âœ… OCR processing completed! Results saved to: {filename}",
        "processing_error": "âŒ Error occurred during processing: {error}",
        "model_loading": "Loading model...",
        "processor_loading": "Loading processor...",
        "client_initializing": "Initializing client...",
        "model_loaded": "Model loading completed",
        "model_load_success": "âœ… Model loaded successfully!",
        "model_path_not_exist": "âŒ Error: Model path does not exist",
        "model_load_failed": "âŒ Model loading failed: {error}",
        "pdf_converting": "Converting PDF to images...",
        "processing_page": "Processing page {page_num}...",
        "processing_image": "Processing image...",
        "generating_markdown": "Generating Markdown file...",
        "processing_complete": "Processing completed"
    }
}

def convert_pdf_to_images(pdf_path, output_dir=None, dpi=200):
    """
    å°†PDFè½¬æ¢ä¸ºå¤šå¼ å›¾ç‰‡
    """
    if not PDF_SUPPORT:
        raise ImportError("pdf2imageæœªå®‰è£…ï¼Œæ— æ³•å¤„ç†PDFæ–‡ä»¶")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
    if output_dir is None:
        output_dir = tempfile.mkdtemp(prefix="pdf_ocr_")
    else:
        os.makedirs(output_dir, exist_ok=True)
    
    # è½¬æ¢PDFä¸ºå›¾ç‰‡
    images = convert_from_path(pdf_path, dpi=dpi)
    
    image_paths = []
    for i, image in enumerate(images):
        image_path = os.path.join(output_dir, f"page_{i+1:03d}.png")
        image.save(image_path, 'PNG')
        image_paths.append(image_path)
    
    return image_paths, output_dir

def process_single_image(image_path, client):
    """
    å¤„ç†å•å¼ å›¾ç‰‡çš„OCR
    """
    image = Image.open(image_path)
    extracted_blocks = client.two_step_extract(image)
    return extracted_blocks

def save_ocr_results_as_formatted_md(all_extracted_blocks, original_path, multipage=False):
    """
    å°†OCRè¯†åˆ«ç»“æœæ¸²æŸ“ä¸ºæ ¼å¼åŒ–çš„Markdowné¡µé¢
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    original_name = os.path.splitext(os.path.basename(original_path))[0]
    
    if multipage:
        filename = f"{original_name}_[OCR_Multipage]_{timestamp}.md"
    else:
        filename = f"{original_name}_[OCR]_{timestamp}.md"
    
    # ç”Ÿæˆæ ¼å¼åŒ–çš„Markdownå†…å®¹
    md_content = generate_formatted_markdown(all_extracted_blocks, original_name, multipage)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)
    # æ„å»ºå®Œæ•´çš„è¾“å‡ºè·¯å¾„
    output_path = os.path.join(output_dir, filename)
    
    # ä¿å­˜æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    return output_path, md_content  # è¿™é‡Œè¿”å›å®Œæ•´è·¯å¾„

def generate_formatted_markdown(all_extracted_blocks, original_name, multipage=False):
    """ç”Ÿæˆæ ¼å¼åŒ–çš„Markdownå†…å®¹"""
    
    content = []
    
    if multipage:
        content.append(f"## OCRè¯†åˆ«ç»“æœ - {original_name} (å¤šé¡µæ–‡æ¡£)\n")
    else:
        content.append(f"## OCRè¯†åˆ«ç»“æœ - {original_name}\n")
        
    content.append(f"*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")
    
    if multipage:
        content.append(f"*æ€»é¡µæ•°: {len(all_extracted_blocks)}*\n")
    
    content.append("\n---\n\n")
    
    # å¤„ç†å¤šé¡µæˆ–å•é¡µå†…å®¹
    if multipage:
        for page_num, page_blocks in enumerate(all_extracted_blocks, 1):
            content.append(f"### ç¬¬ {page_num} é¡µ\n\n")
            content.extend(process_blocks(page_blocks))
            if page_num < len(all_extracted_blocks):  # ä¸æ˜¯æœ€åä¸€é¡µ
                content.append("\n---\n\n")
    else:
        content.extend(process_blocks(all_extracted_blocks))
    
    # æ·»åŠ æ•°å­¦å…¬å¼æ”¯æŒè¯´æ˜
    content.append("\n---\n")
    content.append("*æœ¬æ–‡æ¡£åŒ…å«æ•°å­¦å…¬å¼ï¼Œå¦‚éœ€æ­£ç¡®æ¸²æŸ“è¯·ç¡®ä¿æŸ¥çœ‹ç¯å¢ƒæ”¯æŒMathJaxæˆ–KaTeX*")
    
    return "".join(content)

def process_blocks(blocks):
    """å¤„ç†å•ä¸ªé¡µé¢çš„å—å†…å®¹"""
    content_lines = []
    
    for i, block in enumerate(blocks):
        block_type = block.get('type', 'unknown')
        block_content = block.get('content')

        # æ£€æŸ¥ block_content æ˜¯å¦ä¸º None æˆ–ç©º
        if block_content is None or not block_content.strip():
            continue
            
        # å»é™¤é¦–å°¾ç©ºç™½
        block_content = block_content.strip()
            
        # æ ¹æ®ç±»å‹å¤„ç†å†…å®¹
        if block_type == 'equation':
            # æ•°å­¦å…¬å¼ - ç›´æ¥ä½¿ç”¨LaTeXæ ¼å¼
            content_lines.append(block_content + "\n\n")
        elif block_type == 'footer':
            # é¡µè„š - å¯ä»¥ç‰¹æ®Šå¤„ç†æˆ–å½“ä½œæ™®é€šæ–‡æœ¬
            content_lines.append(f"*{block_content}*\n\n")
        elif block_type == 'header':
            # é¡µçœ‰ - å¯ä»¥ç‰¹æ®Šå¤„ç†æˆ–å½“ä½œæ™®é€šæ–‡æœ¬
            content_lines.append(f"*{block_content}*\n\n")
        else:
            # å…¶ä»–æ–‡æœ¬ç±»å‹
            content_lines.append(block_content + "\n\n")
    
    return content_lines

def initialize_model(model_path, current_lang, progress=gr.Progress()):
    """
    åˆå§‹åŒ–æ¨¡å‹å’Œå¤„ç†å™¨
    """
    global global_model, global_processor, global_client
    
    try:
        progress(0.1, desc=TEXTS[current_lang]["model_loading"])
        
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            return None, TEXTS[current_lang]["model_path_not_exist"]
        
        global_model = Qwen2VLForConditionalGeneration.from_pretrained(
            model_path,
            local_files_only=True,
            dtype="auto",
            device_map="auto"
        )

        progress(0.6, desc=TEXTS[current_lang]["processor_loading"])
        
        global_processor = AutoProcessor.from_pretrained(
            model_path,
            use_fast=True
        )
        
        progress(0.9, desc=TEXTS[current_lang]["client_initializing"])
        
        global_client = MinerUClient(
            backend="transformers",
            model=global_model,
            processor=global_processor
        )
        
        progress(1.0, desc=TEXTS[current_lang]["model_loaded"])
        return global_client, TEXTS[current_lang]["model_load_success"]
        
    except Exception as e:
        return None, TEXTS[current_lang]["model_load_failed"].format(error=str(e))

def process_file(input_file, current_lang, progress=gr.Progress()):
    """
    å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    """
    global global_model, global_processor, global_client
    
    if global_model is None or global_processor is None or global_client is None:
        return gr.update(), gr.update(), TEXTS[current_lang]["model_not_loaded"]
    
    if input_file is None:
        return gr.update(), gr.update(), TEXTS[current_lang]["no_file_uploaded"]
    
    temp_dir = None
    status_messages = []
    
    # å®šä¹‰è¿›åº¦åŒºé—´
    progress_ranges = {
        'pdf_conversion': (0.0, 0.2),      # 20%
        'page_processing': (0.2, 0.9),     # 70% 
        'markdown_generation': (0.9, 0.95), # 5%
        'completion': (0.95, 1.0)           # 5%
    }
    
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        file_ext = os.path.splitext(input_file.name)[1].lower()
        status_messages.append(TEXTS[current_lang]["file_detected"].format(filename=os.path.basename(input_file.name)))
        
        if file_ext == '.pdf':
            if not PDF_SUPPORT:
                return gr.update(), gr.update(), TEXTS[current_lang]["pdf_not_supported"]
            
            status_messages.append(TEXTS[current_lang]["pdf_detected"])
            progress(progress_ranges['pdf_conversion'][1], desc=TEXTS[current_lang]["pdf_converting"])
            
            # è½¬æ¢PDFä¸ºå›¾ç‰‡
            image_paths, temp_dir = convert_pdf_to_images(input_file.name)
            status_messages.append(TEXTS[current_lang]["pdf_converted"].format(page_count=len(image_paths)))
            
            # å¤„ç†æ¯ä¸€é¡µ - ä½¿ç”¨è¿›åº¦åŒºé—´è®¡ç®—
            all_blocks = []
            page_start, page_end = progress_ranges['page_processing']
            for i, image_path in enumerate(image_paths):
                # è®¡ç®—å½“å‰é¡µé¢å¤„ç†çš„è¿›åº¦
                current_progress = page_start + (i / len(image_paths)) * (page_end - page_start)
                progress(current_progress, desc=TEXTS[current_lang]["processing_page"].format(page_num=i+1))
                blocks = process_single_image(image_path, global_client)
                all_blocks.append(blocks)
                status_messages.append(TEXTS[current_lang]["page_processed"].format(page_num=i+1))
            
            progress(progress_ranges['markdown_generation'][1], desc=TEXTS[current_lang]["generating_markdown"])
            # ä¿å­˜ä¸ºå¤šé¡µMarkdown
            md_file, md_content = save_ocr_results_as_formatted_md(all_blocks, input_file.name, multipage=True)
            
        elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            status_messages.append(TEXTS[current_lang]["image_detected"])
            # å•å¼ å›¾ç‰‡å¤„ç†ç›´æ¥ä½¿ç”¨é¡µé¢å¤„ç†çš„ç»“æŸç‚¹
            progress(progress_ranges['page_processing'][1], desc=TEXTS[current_lang]["processing_image"])
            
            # å¤„ç†å•å¼ å›¾ç‰‡
            blocks = process_single_image(input_file.name, global_client)
            status_messages.append(TEXTS[current_lang]["image_processed"])
            
            progress(progress_ranges['markdown_generation'][1], desc=TEXTS[current_lang]["generating_markdown"])
            md_file, md_content = save_ocr_results_as_formatted_md(blocks, input_file.name, multipage=False)
            
        else:
            return gr.update(), gr.update(), TEXTS[current_lang]["unsupported_format"].format(file_ext=file_ext)
        
        progress(progress_ranges['completion'][1], desc=TEXTS[current_lang]["processing_complete"])
        status_messages.append(TEXTS[current_lang]["ocr_completed"].format(filename=md_file))
        
        # è¿”å›ç»“æœ
        status_text = "\n".join(status_messages)
        return md_content, md_file, status_text
        
    except Exception as e:
        status_messages.append(TEXTS[current_lang]["processing_error"].format(error=str(e)))
        status_text = "\n".join(status_messages)
        return gr.update(), gr.update(), status_text
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_dir:
            cleanup_temp_files(temp_dir)

def cleanup_temp_files(temp_dir):
    """
    æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    """
    if temp_dir and os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)

def create_gradio_interface():
    """
    åˆ›å»ºGradioç•Œé¢
    """
    with gr.Blocks(title="PDF OCR based on MinerU2.5-1.2B", theme=gr.themes.Soft()) as demo:
        # è¯­è¨€çŠ¶æ€
        current_lang = gr.State(value="zh")
        
        # æ ‡é¢˜è¡Œ
        with gr.Column():
            title_md = gr.Markdown("# PDF OCR based on MinerU2.5-1.2B")
            with gr.Row():
                with gr.Column(scale=5):
                    subtitle_md = gr.Markdown("åŸºäº MinerU2.5-1.2B OCR å¤§æ¨¡å‹çš„ PDF å’Œå›¾ç‰‡æ–‡æ¡£è¯†åˆ«å·¥å…·")
                with gr.Column(scale=1):
                    language_btn = gr.Button("English", size="sm")
        
        with gr.Row():
            with gr.Column(scale=2):
                # æ¨¡å‹è·¯å¾„è¾“å…¥
                model_path = gr.Textbox(
                    label="æ¨¡å‹è·¯å¾„",
                    placeholder="è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„...ï¼ˆå¦‚ä¸ºDocker,è¾“å…¥ /app/checkpoints ï¼‰",
                    lines=2,        # æ˜¾ç¤ºè¡Œæ•°
                    max_lines=3,    # æœ€å¤§è¡Œæ•°ï¼Œè¾“å…¥è¿‡é•¿æ—¶è‡ªåŠ¨æ»šåŠ¨
                )
                
                # æ¨¡å‹åŠ è½½æŒ‰é’®
                load_model_btn = gr.Button("åŠ è½½æ¨¡å‹", variant="primary")
                
                # æ–‡ä»¶ä¸Šä¼ 
                file_input = gr.File(
                    label="ä¸Šä¼ æ–‡ä»¶",
                    file_types=[".pdf", ".jpg", ".jpeg", ".png", ".bmp"],
                    file_count="single"  # æ˜ç¡®æŒ‡å®šå•æ–‡ä»¶
                )
                
                # å¤„ç†æŒ‰é’®
                process_btn = gr.Button("å¼€å§‹OCRè¯†åˆ«", variant="primary")
            
            with gr.Column(scale=3):
                # çŠ¶æ€æ˜¾ç¤º
                status_output = gr.Textbox(
                    label="å¤„ç†çŠ¶æ€",
                    lines=10,
                    max_lines=15,
                    interactive=False
                )
                
                # ç»“æœæ˜¾ç¤º
                result_output = gr.Textbox(
                    label="è¯†åˆ«ç»“æœ (Markdownæ ¼å¼)",
                    lines=20,
                    max_lines=25,
                    show_copy_button=True
                )
                
                # æ–‡ä»¶ä¸‹è½½
                file_output = gr.File(
                    label="ä¸‹è½½ç»“æœæ–‡ä»¶",
                    file_types=[".md"]
                )
        
        # è¯´æ˜åŒºåŸŸ
        with gr.Row(equal_height=True):
            gr.Column(scale=1, min_width=0)
            with gr.Column(scale=3):
                gr.Markdown("---")
                instructions_title = gr.Markdown("### ä½¿ç”¨è¯´æ˜")
                instructions_content = gr.Markdown("""
                1. **è®¾ç½®æ¨¡å‹è·¯å¾„**: è¾“å…¥ `MinerU2.5-1.2B` æ¨¡å‹æ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„ï¼ˆå¦‚ä¸ºDocker,è¾“å…¥ /app/checkpoints ï¼‰
                2. **ç‚¹å‡»åŠ è½½æ¨¡å‹**: ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆï¼ˆçŠ¶æ€æ æ˜¾ç¤ºæˆåŠŸï¼‰
                3. **ä¸Šä¼ æ–‡ä»¶**: æ”¯æŒ PDFã€JPGã€JPEGã€PNGã€BMP æ ¼å¼
                4. **å¼€å§‹è¯†åˆ«**: ç‚¹å‡»å¼€å§‹OCRè¯†åˆ«æŒ‰é’®ï¼Œç­‰å¾…å¤„ç†å®Œæˆ
                5. **æŸ¥çœ‹ç»“æœ**: åœ¨å³ä¾§æŸ¥çœ‹è¯†åˆ«ç»“æœå’Œä¸‹è½½Markdownæ–‡ä»¶
                """)
                
                supported_formats_title = gr.Markdown("### æ”¯æŒçš„æ ¼å¼")
                supported_formats_content = gr.Markdown("""
                - PDF æ–‡æ¡£ï¼ˆå¤šé¡µè‡ªåŠ¨å¤„ç†ï¼‰
                - å›¾ç‰‡æ–‡ä»¶: JPG, JPEG, PNG, BMP
                """)
                
                notes_title = gr.Markdown("### æ³¨æ„äº‹é¡¹")
                notes_content = gr.Markdown("""
                - å¤„ç†å¤§å‹PDFæ–‡ä»¶å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
                - ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®ä¸”åŒ…å«å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶
                """)
            gr.Column(scale=1, min_width=0)
        
        # è¯­è¨€åˆ‡æ¢å‡½æ•°
        def switch_language(lang):
            new_lang = "en" if lang == "zh" else "zh"
            texts = TEXTS[new_lang]
            
            # ç”Ÿæˆè¯´æ˜å†…å®¹
            instructions_text = "\n".join(texts["instructions"])
            supported_formats_text = "\n".join([f"- {item}" for item in texts["supported_formats"]])
            notes_text = "\n".join([f"- {item}" for item in texts["notes"]])
            
            return [
                gr.update(value=f"# {texts['title']}"),  # title_md
                gr.update(value=texts['subtitle']),     # subtitle_md
                gr.update(label=texts['model_path_label'], placeholder=texts['model_path_placeholder']),  # model_path
                gr.update(value=texts['load_model_btn']), # load_model_btn
                gr.update(label=texts['file_input_label']), # file_input
                gr.update(value=texts['process_btn']),    # process_btn
                gr.update(label=texts['status_output_label']),  # status_output
                gr.update(label=texts['result_output_label']),  # result_output
                gr.update(label=texts['file_output_label']), # file_output
                gr.update(value=f"### {texts['instructions_title']}"),  # instructions_title
                gr.update(value=instructions_text),     # instructions_content
                gr.update(value=f"### {texts['supported_formats_title']}"),  # supported_formats_title
                gr.update(value=supported_formats_text), # supported_formats_content
                gr.update(value=f"### {texts['notes_title']}"),  # notes_title
                gr.update(value=notes_text),            # notes_content
                gr.update(value=texts['language_btn']),   # language_btn
                new_lang                                        # current_lang
            ]
        
        # äº‹ä»¶å¤„ç†
        load_model_btn.click(
            fn=initialize_model,
            inputs=[model_path, current_lang],
            outputs=[gr.Number(visible=False), status_output]
        )

        process_btn.click(
            fn=process_file,
            inputs=[file_input, current_lang],
            outputs=[result_output, file_output, status_output]
        )
        
        # è¯­è¨€åˆ‡æ¢äº‹ä»¶
        language_btn.click(
            fn=switch_language,
            inputs=[current_lang],
            outputs=[
                title_md, subtitle_md, model_path, load_model_btn, file_input,
                process_btn, status_output, result_output, file_output,
                instructions_title, instructions_content, supported_formats_title,
                supported_formats_content, notes_title, notes_content, language_btn,
                current_lang
            ]
        )
    
    return demo

if __name__ == "__main__":
    # å¯åŠ¨Gradioç•Œé¢
    demo = create_gradio_interface()
    demo.launch(
        max_file_size="1000mb",         # é™åˆ¶ä¸Šä¼ æ–‡ä»¶å¤§å°
        server_name="0.0.0.0",          # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=8100,               # ç«¯å£å·
        share=False,                    # ä¸ç”Ÿæˆå…¬å…±é“¾æ¥
        inbrowser=True                  # è‡ªåŠ¨åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
    )